import tensorflow as tf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import os
from datetime import datetime
from matplotlib import pyplot as plt
from skimage import io
from skimage import img_as_ubyte


# Global constants
image_row = 300
image_column = 400
filenames = []
numOfImages = 0

# Print minimum and maximum values
def printMinMaxValues(arr):
    print(arr.min())
    print(arr.max())
    print(arr.dtype)


# Preprocessing images
def preprocessImages():
    approachFolders = [
        'images/DRFI/',
        'images/DSR/',
        'images/GMR/',
        'images/MC/',
        'images/RBD/'
    ]

    global numOfImages
    global filenames

    numOfImages = len([name for name in os.listdir(approachFolders[0]) if os.path.isfile(os.path.join(approachFolders[0], name))])

    X = np.zeros((numOfImages*image_column*image_row, 5), dtype=np.uint8)
    cnt = 0
    
    # Filename is generated by removing _DRFI.png from the filenames in the folder images/DRFI which is expected to contain the images of the dataset along with _DRFI 
	for filename in approachFolders[0]:
        filename = filename[:-9] + ".png"
        filenames.append(filename)

    for folder in approachFolders:
        newImgs = np.empty((0, 1), dtype=np.uint8)
        for filename in os.listdir(folder):
            img = io.imread(os.path.join(folder, filename), isGray=True)
            img = img.reshape(image_row*image_column, 1)
            newImgs = np.concatenate((newImgs, img), axis=0)
        X[:, cnt] = newImgs.flatten()
        cnt = cnt + 1

    return X


def reverse_process_image(finalImgArr):
    outputFolder = 'images/OP/'
    global filenames
    print('final Image array')
    print(finalImgArr.shape)
    # Reverse Normalization
    scaler = MinMaxScaler()

    global numOfImages
    for cnt in range(numOfImages):

        # Splitting into image array of size 300*400
        currentStart = cnt * (image_row*image_column)
        currentStop = (cnt+1) * (image_row*image_column)
        current_array = finalImgArr[currentStart:currentStop, :]
        
        current_array = np.round(scaler.fit_transform(current_array), 6)
        
        finalImage = img_as_ubyte(current_array)
        finalImage = finalImage.reshape(image_row, image_column)

        io.imsave(os.path.join(outputFolder)+filenames[cnt], finalImage)


# Model Constants
training_epochs = 100
neurons_in_hlayer = 100
learning_rate = 0.03

# Get X and y Values from preprocessing
X = preprocessImages()

total_train_images = int(numOfImages*0.8)
total_test_images = numOfImages - total_train_images
slices = int(numOfImages*0.8) * image_row*image_column
# print(slices)
X_train, X_test = np.vsplit(X, [slices])

n_samples, n_features = X_train.shape
n_classes = 1

# Input and Expected Output of the neural networks
xs = tf.placeholder("uint8", [None, n_features], name='XtoNN')
ys = tf.placeholder("float32", [None, 1], name='YfromNN')
xs_minmax = tf.cast(tf.divide(tf.subtract(xs, tf.reduce_min(xs)),
                              tf.subtract(tf.reduce_max(xs), tf.reduce_min(xs))), tf.float32)

# Hidden Layer
weightsH = tf.Variable(tf.truncated_normal([n_features, neurons_in_hlayer], mean=0,
                                     stddev=1 / np.sqrt(n_features)), name='weights1')
biasesH = tf.Variable(tf.truncated_normal([neurons_in_hlayer],mean=0, stddev=1 / np.sqrt(n_features)), name='biases1')
yValH = tf.nn.sigmoid(tf.add(tf.matmul(xs_minmax, weightsH),biasesH), name='activationLayer1')

# Output Layer
WeightsO = tf.Variable(tf.truncated_normal([neurons_in_hlayer, n_classes], mean=0, stddev = 1/np.sqrt(n_features)),
                                           name='weightsOut')
biasesO = tf.Variable(tf.truncated_normal([n_classes], mean=0, stddev=1 / np.sqrt(n_features)), name='biasesOut')
yPred = tf.cast(tf.add(tf.matmul(yValH, WeightsO), biasesO), dtype=tf.float32, name='yOutput')

# Cost function
cost = tf.reduce_mean(tf.square(yPred-ys, name='cost'))

# Optimizer
train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

with tf.Session() as sess:
    saver = tf.train.Saver()
    saver.restore(sess, os.path.dirname(os.path.realpath(__file__)) + '/model/model_save2.ckpt')

    # All Images predict
    y_final_predict = np.empty((0, 1), np.float32)
    for i in range(numOfImages):
        current_start = i * (image_row * image_column)
        current_stop = (i + 1) * (image_row * image_column)
        current_value = sess.run(yPred, feed_dict={xs: X[current_start:current_stop, :].reshape(image_column * image_row,
                                                                                                n_features)})
        y_final_predict = np.append(y_final_predict, current_value)
    # y_final_predict = sess.run(yPred, feed_dict={xs: X})
    y_final_predict = y_final_predict.reshape((image_column*image_row*numOfImages, 1))
    
    # Final Processing
    reverse_process_image(y_final_predict)
