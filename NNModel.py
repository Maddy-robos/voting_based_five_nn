import tensorflow as tf
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import os
from datetime import datetime
from matplotlib import pyplot as plt
from skimage import io
from skimage import img_as_ubyte
import math

# Global constants
image_row = 300
image_column = 400
filenames = []
num_of_images = 0

# Print minimum and maximum values
def printMinMaxValues(arr):
    print(arr.min())
    print(arr.max())
    print(arr.dtype)


# Preprocessing images
def preprocessImages():
    approachFolders = [
        'images/DRFI/',
        'images/DSR/',
        'images/GMR/',
        'images/MC/',
        'images/RBD/'
    ]

    global num_of_images
    global filenames

    groundTruthFolder = 'images/GTRUTH/'
    Y = np.empty((0, 1), dtype=np.uint8)

    # First we calculate Y so as to get the number of images for training and testing
    for filename in os.listdir(groundTruthFolder):
        filenames.append(filename)
        img = io.imread(os.path.join(groundTruthFolder, filename), isGray=True)
        img = img.reshape(image_row, image_column)
        if img is not None:
            Y = np.append(Y, img.reshape((image_row*image_column, 1)), axis=0)
            num_of_images = num_of_images + 1

    X = np.zeros((num_of_images*image_column*image_row, 5), dtype=np.uint8)
    cnt = 0
    for folder in approachFolders:
        newImgs = np.empty((0, 1), dtype=np.uint8)
        for filename in os.listdir(folder):
            img = io.imread(os.path.join(folder, filename), isGray=True)
            img = img.reshape(image_row*image_column, 1)
            newImgs = np.concatenate((newImgs, img), axis=0)
        X[:, cnt] = newImgs.flatten()
        cnt = cnt + 1

    return X, Y


def reverseProcessImage(finalImgArr, no_images=None):
    outputFolder = 'images/OP/'
    global filenames

    # Reverse Normalization
    scaler = MinMaxScaler()

    global num_of_images
    for cnt in range(num_of_images):

        # Splitting into image array of size 300*400
		# Current start and stop denotes the starting and ending pixels of each image as depicted by the variable cnt
        currentStart = cnt * (image_row*image_column)
        currentStop = (cnt+1) * (image_row*image_column)
        currentArray = finalImgArr[currentStart:currentStop, :]
        # Scaling the array using min max scaler for each and every image
        currentArray = np.round(scaler.fit_transform(currentArray), 6)
        # Final Image can be generated by converting the float values into unsigned int values
        finalImage = img_as_ubyte(currentArray)
        finalImage = finalImage.reshape(image_row, image_column)

        io.imsave(os.path.join(outputFolder)+filenames[cnt], finalImage)


# Model Constants
training_epochs = 50
neurons_in_hlayer = 100
learning_rate = 0.03
batch_per_epoch = 50

print('Preprocessing - Loading images from the given folder...')
# Get X and y Values from preprocessing
X, Y = preprocessImages()

total_train_images = int(num_of_images*0.8)
total_test_images = num_of_images - total_train_images
slices = int(num_of_images*0.8) * image_row*image_column

X_train, X_test = np.vsplit(X, [slices])
Y_train, Y_test = np.vsplit(Y, [slices])

# Scaling only the Ground Truth. The images are scaled in batches using Tensorflow variables
scaler = MinMaxScaler()
Y_train = scaler.fit_transform(Y_train)
Y_test = scaler.fit_transform(Y_test)

n_samples, n_features = X_train.shape
# Since Regression n_classes is set to 1
n_classes = 1

# Input and Expected Output of the neural networks which is expected to contain either a single image or a batch of images that are scaled together
xs = tf.placeholder("uint8", [None, n_features], name='XtoNN')
ys = tf.placeholder("float32", [None, 1], name='YfromNN')
xs_minmax = tf.cast(tf.divide(tf.subtract(xs, tf.reduce_min(xs)),
                              tf.subtract(tf.reduce_max(xs), tf.reduce_min(xs))), tf.float32)

# Hidden Layer
weightsH = tf.Variable(tf.truncated_normal([n_features, neurons_in_hlayer], mean=0,
                                     stddev=1 / np.sqrt(n_features)), name='weights1')
biasesH = tf.Variable(tf.truncated_normal([neurons_in_hlayer],mean=0, stddev=1 / np.sqrt(n_features)), name='biases1')
yValH = tf.nn.sigmoid(tf.add(tf.matmul(xs_minmax, weightsH),biasesH), name='activationLayer1')

# Output Layer
WeightsO = tf.Variable(tf.truncated_normal([neurons_in_hlayer, n_classes], mean=0, stddev = 1/np.sqrt(n_features)),
                                           name='weightsOut')
biasesO = tf.Variable(tf.truncated_normal([n_classes], mean=0, stddev=1 / np.sqrt(n_features)), name='biasesOut')
yPred = tf.cast(tf.add(tf.matmul(yValH, WeightsO), biasesO), dtype=tf.float32, name='yOutput')

# Cost function
cost = tf.reduce_mean(tf.square(yPred-ys, name='cost'))

# Optimizer
train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

print('***** Training of the Neural Network has begun. Do not close this window ******')
# Saving start time to estimate the time taken for the whole training
startTime = datetime.now()
# Session
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    sess.run(tf.local_variables_initializer())
    saver = tf.train.Saver()
    cost_list = []
    for i in range(training_epochs):
        currentEpochCost = 0
        total_trained = 0
        for j in range(0, total_train_images, batch_per_epoch):

            # Divide the whole training images into batches using current_start and current_stop variables that are defined using the j value
            current_start = j * (image_row * image_column)
            batch_per_current_epoch = batch_per_epoch if (total_train_images-total_trained >= batch_per_epoch) else total_train_images-total_trained
            current_stop = (j + batch_per_current_epoch) * (image_row * image_column)

            # Running the trainer for the current batch
            currentEpochCost, trainer = sess.run([cost, train], feed_dict={xs: X_train[current_start:current_stop, :]
                     .reshape(image_column*image_row*batch_per_current_epoch, n_features),
                                                   ys: Y_train[current_start:current_stop]
                     .reshape(image_column*image_row*batch_per_current_epoch, n_classes)})
            total_trained = total_trained + batch_per_epoch
        # Current epoch cost is set to be the final cost of the final batch in the current epoch
        cost_list.append(currentEpochCost)
        print('Epoch ', (i+1), ': Final Image Cost = ', currentEpochCost)

    # Final time taken for the training
    timeTaken = datetime.now() - startTime
    print('Time Taken: ', timeTaken)

    # Saving the Model
    save_path = saver.save(sess, os.path.dirname(os.path.realpath(__file__)) + '\model\model_save2.ckpt')
    print('Model saved at ', save_path)
	
    # Plotting Cost vs Number of Epochs
    plt.figure()
    plt.plot(np.arange(len(cost_list)), np.array(cost_list))
    output_folder = 'images/CMP/'
    plt.xlabel("Time in epochs")
    plt.ylabel("Cost Function")
    plt.savefig(os.path.join(output_folder)+"cost_learning.png")
    plt.close()

    # All Images predict
    yFinalPredict = np.empty((0, 1))
    print('Testing over all images')
    for i in range(num_of_images):
        current_start = i * (image_row * image_column)
        current_stop = (i + 1) * (image_row * image_column)
        yFinalPredict = np.append(yFinalPredict, sess.run(yPred, feed_dict={xs: X[current_start:current_stop, :]
                                             .reshape(image_column * image_row, n_features),
                                                                       ys: Y[current_start:current_stop]
                                             .reshape(image_column * image_row, n_classes)}), axis=0)

    # Final Processing
    reverseProcessImage(Y, yFinalPredict)
